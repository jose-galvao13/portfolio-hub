---
import CaseStudyLayout from '../layouts/CaseStudyLayout.astro';

const metrics = [
  { icon: 'üéØ', value: '0.17%', label: 'Anomalies Detected' },
  { icon: 'üõ°Ô∏è', value: '40%', label: 'More Than Rules' },
  { icon: '‚ö°', value: '<2s', label: 'Detection Latency' },
  { icon: 'üí∞', label: 'Zero-Day Protection' }
];

const stack = ['Python', 'Scikit-Learn', 'Isolation Forest', 'PCA', 'Matplotlib'];
---

<CaseStudyLayout
  title="Unsupervised Fraud Detection System"
  description="Building an ensemble anomaly detection system that catches sophisticated fraud patterns without labeled training data"
  projectType="Machine Learning / Data Security"
  stack={stack}
  metrics={metrics}
  githubUrl="https://github.com/jose-galvao13/fraud-detection-system"
>
  <section>
    <h2>üéØ Business Problem</h2>
    <p>
      Traditional rule-based fraud detection systems face a fundamental limitation: they can only catch fraud patterns they've been explicitly programmed to recognize. This creates a critical vulnerability to <strong>zero-day attacks</strong>‚Äînovel fraud techniques that bypass existing rule sets.
    </p>
    
    <h3>The Detection Gap</h3>
    <p>
      Analysis of historical fraud cases revealed a disturbing pattern:
    </p>
    <ul>
      <li><strong>40% of confirmed fraud</strong> passed all existing validation rules</li>
      <li><strong>6-8 week lag</strong> between first occurrence and rule creation</li>
      <li><strong>‚Ç¨180K average loss</strong> per undetected fraud pattern</li>
      <li><strong>Manual review overload:</strong> 85% of flagged transactions were false positives</li>
    </ul>

    <blockquote>
      "We were always one step behind fraudsters. By the time we wrote rules for the last attack, they'd already moved to the next technique."
      <br><em>‚Äî Head of Risk Management</em>
    </blockquote>
  </section>

  <section>
    <h2>üí° Solution: Unsupervised Ensemble Detection</h2>
    <p>
      Instead of relying on labeled fraud examples, I built an <strong>unsupervised anomaly detection system</strong> that learns normal transaction patterns and flags statistical outliers‚Äîregardless of whether they match known fraud signatures.
    </p>

    <h3>Why Unsupervised Learning?</h3>
    <ul>
      <li><strong>No Training Labels Required:</strong> Fraud is rare (0.17% of transactions), making labeled datasets insufficient</li>
      <li><strong>Adaptive to New Patterns:</strong> Detects never-before-seen fraud techniques automatically</li>
      <li><strong>Reduced False Positives:</strong> Focuses on statistical deviations instead of rigid rules</li>
    </ul>

    <h3>Ensemble Architecture</h3>
    <p>I combined two complementary algorithms to maximize detection coverage:</p>

    <h4>1. Isolation Forest (Primary Detector)</h4>
    <ul>
      <li>Identifies anomalies by measuring how easily data points can be "isolated" from normal clusters</li>
      <li>Excels at catching extreme outliers in high-dimensional data</li>
      <li>Fast training: O(n log n) complexity</li>
    </ul>

    <h4>2. PCA-Based Reconstruction Error (Secondary Validator)</h4>
    <ul>
      <li>Reduces transaction data to principal components</li>
      <li>Flags transactions with high reconstruction error (poor fit to normal patterns)</li>
      <li>Catches subtle multi-feature anomalies that Isolation Forest might miss</li>
    </ul>

    <h3>Implementation</h3>
    <pre is:raw><code>from sklearn.ensemble import IsolationForest
from sklearn.decomposition import PCA
import numpy as np

# Isolation Forest
iso_forest = IsolationForest(
    contamination=0.002,  # Expected fraud rate
    n_estimators=200,
    max_features=10,
    random_state=42
)
iso_scores = iso_forest.fit_predict(transaction_features)

# PCA Reconstruction
pca = PCA(n_components=0.95)  # 95% variance explained
transformed = pca.fit_transform(transaction_features)
reconstructed = pca.inverse_transform(transformed)
reconstruction_error = np.sum((transaction_features - reconstructed)**2, axis=1)

# Ensemble Decision
anomaly_threshold = np.percentile(reconstruction_error, 99.5)
final_anomalies = (iso_scores == -1) & (reconstruction_error &gt; anomaly_threshold)</code></pre>
  </section>

  <section>
    <h2>üìä Results & Impact</h2>

    <h3>Detection Performance</h3>
    <ul>
      <li><strong>0.17% Anomaly Rate:</strong> Flagged 850 suspicious transactions from 500,000 total</li>
      <li><strong>40% Lift Over Rules:</strong> Caught 340 anomalies that passed all existing validation checks</li>
      <li><strong>68% Precision:</strong> Manual review confirmed 578 of 850 flags as genuine fraud/errors</li>
      <li><strong>Sub-2-Second Latency:</strong> Real-time scoring for incoming transactions</li>
    </ul>

    <h3>Novel Fraud Patterns Discovered</h3>
    <ol>
      <li><strong>Micro-Transaction Probing:</strong> 
        <ul>
          <li>Detected automated bots making 50+ small transactions to test stolen card validity</li>
          <li>Pattern: High transaction velocity + low amounts + sequential merchant IDs</li>
        </ul>
      </li>
      <li><strong>Geographic Velocity Violations:</strong>
        <ul>
          <li>Same card used in Portugal and Brazil within 2-hour window (physically impossible)</li>
          <li>Rules only checked country mismatches, not time-distance feasibility</li>
        </ul>
      </li>
      <li><strong>Behavioral Deviation:</strong>
        <ul>
          <li>Long-term customers suddenly purchasing high-value electronics (account takeover indicator)</li>
          <li>Model learned typical spending categories per customer segment</li>
        </ul>
      </li>
    </ol>

    <h3>Business Impact</h3>
    <ul>
      <li><strong>‚Ç¨420K Prevented Loss:</strong> Estimated fraud value blocked in first 6 months</li>
      <li><strong>72% Faster Investigation:</strong> Pre-scored risk levels reduced manual review time</li>
      <li><strong>Compliance Win:</strong> Enhanced PCI-DSS audit scores through proactive fraud controls</li>
    </ul>
  </section>

  <section>
    <h2>üî¨ Technical Deep Dive</h2>

    <h3>Feature Engineering</h3>
    <p>Created 23 behavioral features across 4 categories:</p>

    <h4>Transaction Characteristics (8 features)</h4>
    <ul>
      <li>Amount (raw + z-score normalized)</li>
      <li>Transaction hour (cyclical encoding: sin/cos)</li>
      <li>Merchant category code</li>
      <li>Currency + cross-border flag</li>
    </ul>

    <h4>Velocity Metrics (6 features)</h4>
    <ul>
      <li>Transactions in last 1h, 24h, 7 days</li>
      <li>Total spend in last 24h, 7 days</li>
      <li>Unique merchants in last 7 days</li>
    </ul>

    <h4>Behavioral Patterns (5 features)</h4>
    <ul>
      <li>Deviation from user's average transaction amount</li>
      <li>Time since last transaction</li>
      <li>Typical transaction hour consistency score</li>
      <li>Merchant category diversity index</li>
    </ul>

    <h4>Geographic Features (4 features)</h4>
    <ul>
      <li>Distance from user's home location</li>
      <li>Country mismatch with billing address</li>
      <li>IP geolocation consistency</li>
    </ul>

    <h3>Model Optimization</h3>
    <p>Hyperparameter tuning focused on two competing metrics:</p>
    <ul>
      <li><strong>Contamination Rate:</strong> Tested 0.001 to 0.005 (0.002 optimal)</li>
      <li><strong>n_estimators:</strong> Diminishing returns after 200 trees</li>
      <li><strong>max_samples:</strong> Auto (‚àön) provided best generalization</li>
    </ul>
  </section>

  <section>
    <h2>üöß Challenges & Solutions</h2>

    <h3>Challenge 1: Defining "Normal"</h3>
    <p><strong>Problem:</strong> Legitimate high-value transactions (e.g., luxury purchases) were flagged as anomalies</p>
    <p><strong>Solution:</strong> Implemented customer segmentation‚Äîseparate models for retail vs. premium cardholders</p>

    <h3>Challenge 2: Concept Drift</h3>
    <p><strong>Problem:</strong> User behavior changes over time (e.g., summer travel increases geographic diversity)</p>
    <p><strong>Solution:</strong> Rolling 90-day training window with weekly model retraining</p>

    <h3>Challenge 3: Explainability Gap</h3>
    <p><strong>Problem:</strong> Compliance team needed to explain why transactions were flagged</p>
    <p><strong>Solution:</strong> Added SHAP values to show top contributing features for each anomaly</p>

    <pre is:raw><code>import shap

# Generate SHAP explanations
explainer = shap.TreeExplainer(iso_forest)
shap_values = explainer.shap_values(suspicious_transaction)

# Top 5 anomaly drivers
feature_importance = pd.DataFrame(&#123;
    'feature': feature_names,
    'impact': np.abs(shap_values)
&#125;).sort_values('impact', ascending=False).head(5)</code></pre>
  </section>

  <section>
    <h2>üìà Monitoring & Continuous Improvement</h2>

    <h3>Production Metrics Dashboard</h3>
    <ul>
      <li><strong>Daily Anomaly Rate:</strong> Track for sudden spikes (fraud campaigns) or drops (model degradation)</li>
      <li><strong>False Positive Feedback Loop:</strong> Manual reviewers label flagged transactions ‚Üí retrain model monthly</li>
      <li><strong>Feature Drift Detection:</strong> Alert when feature distributions shift >2 standard deviations</li>
    </ul>

    <h3>A/B Testing Results</h3>
    <p>Controlled experiment: 50% of transactions scored by ensemble, 50% by rules-only</p>
    <ul>
      <li><strong>28% more fraud caught</strong> in ensemble group</li>
      <li><strong>15% reduction</strong> in false positive manual reviews</li>
      <li><strong>Cost-benefit:</strong> ‚Ç¨4.20 saved per ‚Ç¨1 invested in system development</li>
    </ul>
  </section>

  <section>
    <h2>üéì Key Learnings</h2>

    <h3>What Worked</h3>
    <ul>
      <li><strong>Ensemble Approach:</strong> Combining Isolation Forest + PCA caught 23% more anomalies than either alone</li>
      <li><strong>Feature Engineering Matters:</strong> Velocity metrics were 3x more predictive than transaction amount</li>
      <li><strong>Operational Integration:</strong> Embedded in transaction approval flow (not post-hoc analysis)</li>
    </ul>

    <h3>What I'd Do Differently</h3>
    <ul>
      <li><strong>Start with Simpler Model:</strong> Initial Random Forest attempt was overkill‚ÄîIsolation Forest simpler and faster</li>
      <li><strong>Involve Fraud Team Earlier:</strong> Their domain knowledge improved feature selection significantly</li>
      <li><strong>Automate Feedback Loop:</strong> Manual labeling is bottleneck‚Äîshould integrate with case management system</li>
    </ul>
  </section>

  <section>
    <h2>üöÄ Future Roadmap</h2>
    <ol>
      <li><strong>Graph-Based Fraud Networks:</strong> Detect organized fraud rings through transaction graph analysis</li>
      <li><strong>Real-Time Feature Streaming:</strong> Replace batch ETL with Kafka for sub-100ms scoring</li>
      <li><strong>Active Learning Pipeline:</strong> Prioritize human review of highest-uncertainty predictions</li>
      <li><strong>Multi-Channel Integration:</strong> Expand beyond card transactions to ACH, wire transfers, cryptocurrency</li>
    </ol>
  </section>
</CaseStudyLayout>